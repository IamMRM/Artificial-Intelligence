{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u\"you're\",\n",
       " u\"you've\",\n",
       " u\"you'll\",\n",
       " u\"you'd\",\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves',\n",
       " u'he',\n",
       " u'him',\n",
       " u'his',\n",
       " u'himself',\n",
       " u'she',\n",
       " u\"she's\",\n",
       " u'her',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'it',\n",
       " u\"it's\",\n",
       " u'its',\n",
       " u'itself',\n",
       " u'they',\n",
       " u'them',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'themselves',\n",
       " u'what',\n",
       " u'which',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'this',\n",
       " u'that',\n",
       " u\"that'll\",\n",
       " u'these',\n",
       " u'those',\n",
       " u'am',\n",
       " u'is',\n",
       " u'are',\n",
       " u'was',\n",
       " u'were',\n",
       " u'be',\n",
       " u'been',\n",
       " u'being',\n",
       " u'have',\n",
       " u'has',\n",
       " u'had',\n",
       " u'having',\n",
       " u'do',\n",
       " u'does',\n",
       " u'did',\n",
       " u'doing',\n",
       " u'a',\n",
       " u'an',\n",
       " u'the',\n",
       " u'and',\n",
       " u'but',\n",
       " u'if',\n",
       " u'or',\n",
       " u'because',\n",
       " u'as',\n",
       " u'until',\n",
       " u'while',\n",
       " u'of',\n",
       " u'at',\n",
       " u'by',\n",
       " u'for',\n",
       " u'with',\n",
       " u'about',\n",
       " u'against',\n",
       " u'between',\n",
       " u'into',\n",
       " u'through',\n",
       " u'during',\n",
       " u'before',\n",
       " u'after',\n",
       " u'above',\n",
       " u'below',\n",
       " u'to',\n",
       " u'from',\n",
       " u'up',\n",
       " u'down',\n",
       " u'in',\n",
       " u'out',\n",
       " u'on',\n",
       " u'off',\n",
       " u'over',\n",
       " u'under',\n",
       " u'again',\n",
       " u'further',\n",
       " u'then',\n",
       " u'once',\n",
       " u'here',\n",
       " u'there',\n",
       " u'when',\n",
       " u'where',\n",
       " u'why',\n",
       " u'how',\n",
       " u'all',\n",
       " u'any',\n",
       " u'both',\n",
       " u'each',\n",
       " u'few',\n",
       " u'more',\n",
       " u'most',\n",
       " u'other',\n",
       " u'some',\n",
       " u'such',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'only',\n",
       " u'own',\n",
       " u'same',\n",
       " u'so',\n",
       " u'than',\n",
       " u'too',\n",
       " u'very',\n",
       " u's',\n",
       " u't',\n",
       " u'can',\n",
       " u'will',\n",
       " u'just',\n",
       " u'don',\n",
       " u\"don't\",\n",
       " u'should',\n",
       " u\"should've\",\n",
       " u'now',\n",
       " u'd',\n",
       " u'll',\n",
       " u'm',\n",
       " u'o',\n",
       " u're',\n",
       " u've',\n",
       " u'y',\n",
       " u'ain',\n",
       " u'aren',\n",
       " u\"aren't\",\n",
       " u'couldn',\n",
       " u\"couldn't\",\n",
       " u'didn',\n",
       " u\"didn't\",\n",
       " u'doesn',\n",
       " u\"doesn't\",\n",
       " u'hadn',\n",
       " u\"hadn't\",\n",
       " u'hasn',\n",
       " u\"hasn't\",\n",
       " u'haven',\n",
       " u\"haven't\",\n",
       " u'isn',\n",
       " u\"isn't\",\n",
       " u'ma',\n",
       " u'mightn',\n",
       " u\"mightn't\",\n",
       " u'mustn',\n",
       " u\"mustn't\",\n",
       " u'needn',\n",
       " u\"needn't\",\n",
       " u'shan',\n",
       " u\"shan't\",\n",
       " u'shouldn',\n",
       " u\"shouldn't\",\n",
       " u'wasn',\n",
       " u\"wasn't\",\n",
       " u'weren',\n",
       " u\"weren't\",\n",
       " u'won',\n",
       " u\"won't\",\n",
       " u'wouldn',\n",
       " u\"wouldn't\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "train = pd.read_csv('labeledTrainData.csv', header=0, delimiter='\\t', quoting=3)\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeofdata=5000\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "    example1 = BeautifulSoup(raw_review, \"html.parser\")\n",
    "    example = example1.get_text()\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    example_=regex.sub(\" \", example)\n",
    "    words=example_.lower().split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stops]\n",
    "    sentence=\" \".join(words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = sizeofdata)\n",
    "import numpy as np\n",
    "test = pd.read_csv(\"labeledTrainData.csv\", header=0, delimiter=\"\\t\",quoting=3 )\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the reviews for better analysis\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = []\n",
    "print \"Cleaning the reviews for better analysis\\n\"\n",
    "for i in xrange(0,sizeofdata):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment 1000 of 25000\n",
      "\n",
      "Sentiment 2000 of 25000\n",
      "\n",
      "Sentiment 3000 of 25000\n",
      "\n",
      "Sentiment 4000 of 25000\n",
      "\n",
      "Sentiment 5000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "for i in xrange(0,sizeofdata):\n",
    "    if ((i + 1) % 1000 == 0):\n",
    "        print \"Sentiment %d of %d\\n\" % (i + 1, num_reviews)\n",
    "    y.append(test[\"sentiment\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] [1 0 0 ... 1 0 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] [0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1\n",
      " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0\n",
      " 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0\n",
      " 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0\n",
      " 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1\n",
      " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1\n",
      " 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1\n",
      " 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
      " 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      " 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1\n",
      " 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0\n",
      " 1 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
      " 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1\n",
      " 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0\n",
      " 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1]\n",
      "Accuracy of the classifier = 82.69999999999999 %\n"
     ]
    }
   ],
   "source": [
    "test_data_features = vectorizer.fit_transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "y=np.array(y)\n",
    "from sklearn import cross_validation\n",
    "x_train, x_test, y_train, y_test=cross_validation.train_test_split(test_data_features,y,test_size=0.20,random_state=0)\n",
    "print x_train, y_train\n",
    "print x_test, y_test\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=.00001)\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred_class=clf.predict(x_test)\n",
    "from sklearn import metrics\n",
    "accuracy=metrics.accuracy_score(y_test, y_pred_class)\n",
    "accuracy=100*accuracy\n",
    "print \"Accuracy of the classifier =\",accuracy,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
